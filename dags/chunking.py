try:
    from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, db
    from sentence_transformers import SentenceTransformer
    MILVUS_AVAILABLE = True
except ImportError:
    MILVUS_AVAILABLE = False

from airflow.providers.postgres.hooks.postgres import PostgresHook
import pandas as pd
import logging

logger = logging.getLogger(__name__)

def load_from_postgres_and_chunk():
    """PostgreSQLì—ì„œ ë²•ë¥  ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì²­í‚¹"""
    
    print("\n" + "="*60)
    print("ğŸ“š PostgreSQLì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œì‘")
    print("="*60)
    
    try:
        pg_hook = PostgresHook(postgres_conn_id='postgres_default')
        
        # 1. ë²•ë¥  ë§ˆìŠ¤í„° ë°ì´í„° í™•ì¸
        print("\n1ï¸âƒ£  ë²•ë¥  ë§ˆìŠ¤í„° ë°ì´í„° ì¡°íšŒ...")
        master_sql = "SELECT case_id, case_name, full_text FROM case_master LIMIT 10"
        master_df = pg_hook.get_pandas_df(master_sql)
        print(f"âœ“ ì¡°íšŒëœ ë²•ë¥  {len(master_df)}ê°œ:")
        print(master_df[['case_id', 'case_name']].to_string())
        
        # 2. ì²­í¬ ë°ì´í„° í™•ì¸
        print("\n2ï¸âƒ£  ì²­í¬ ë°ì´í„° ì¡°íšŒ...")
        chunk_sql = """
            SELECT id, case_id, level, content 
            FROM case_chunks 
            LIMIT 20
        """
        chunk_df = pg_hook.get_pandas_df(chunk_sql)
        print(f"âœ“ ì¡°íšŒëœ ì²­í¬ ì´ {len(chunk_df)}ê°œ:")
        print(f"  - ì¡° ë‹¨ìœ„: {len(chunk_df[chunk_df['level']=='ì¡°'])}ê°œ")
        print(f"  - í•­/í˜¸ ë‹¨ìœ„: {len(chunk_df[chunk_df['level']=='í•­/í˜¸'])}ê°œ")
        
        if len(chunk_df) > 0:
            print("\nğŸ“„ ìƒ˜í”Œ ì²­í¬ ë°ì´í„°:")
            for idx, row in chunk_df.head(3).iterrows():
                print(f"\n   [{row['level']}] Case {row['case_id']} - ID {row['id']}")
                print(f"   ë‚´ìš©: {row['content'][:100]}...")
        
        return master_df, chunk_df
    
    except Exception as e:
        print(f"âœ— PostgreSQL ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def initialize_milvus_collection():
    """Milvus Collection ì´ˆê¸°í™”"""
    
    print("\n" + "="*60)
    print("ğŸ”Œ Milvus Collection ì´ˆê¸°í™”")
    print("="*60)
    
    try:
        # Milvus ì—°ê²°
        print("\n1ï¸âƒ£  Milvus ì—°ê²° (192.168.1.222:19530)...")
        connections.connect(
            alias="default",
            host="192.168.1.222",
            port=19530,
            pool_size=10
        )
        print("âœ“ Milvus ì—°ê²° ì„±ê³µ")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        print("\n2ï¸âƒ£  legal_db ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸...")
        try:
            db.create_database("legal_db")
            print("âœ“ legal_db ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
        except:
            print("âœ“ legal_db ë°ì´í„°ë² ì´ìŠ¤ ì´ë¯¸ ì¡´ì¬")
        
        db.using_database("legal_db")
        
        # Collection í™•ì¸/ìƒì„±
        print("\n3ï¸âƒ£  legal_chunks_v1 Collection í™•ì¸...")
        collection_name = "legal_chunks_v1"
        
        if collection_name in db.list_collections():
            print(f"âœ“ {collection_name} Collection ì´ë¯¸ ì¡´ì¬")
            collection = Collection(name=collection_name)
        else:
            # ìƒˆ Collection ìƒì„±
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
                FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=256),
                FieldSchema(name="case_id", dtype=DataType.INT64),
                FieldSchema(name="level", dtype=DataType.VARCHAR, max_length=32),
                FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=8192),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384)
            ]
            schema = CollectionSchema(fields, description="Legal Document Chunks")
            collection = Collection(name=collection_name, schema=schema)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            index_params = {
                "metric_type": "L2",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 128}
            }
            collection.create_index(field_name="embedding", index_params=index_params)
            print(f"âœ“ {collection_name} Collection ìƒì„± ì™„ë£Œ")
        
        return collection
    
    except Exception as e:
        print(f"âœ— Milvus ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def generate_and_store_embeddings(chunk_df, collection):
    """ì²­í¬ ë°ì´í„°ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  Milvusì— ì €ì¥"""
    
    print("\n" + "="*60)
    print("ğŸ§  ì„ë² ë”© ìƒì„± ë° Milvus ì €ì¥")
    print("="*60)
    
    try:
        # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print("\n1ï¸âƒ£  ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘... (all-MiniLM-L6-v2)")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (384ì°¨ì›)")
        
        # 2. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        print(f"\n2ï¸âƒ£  {len(chunk_df)}ê°œ ì²­í¬ì˜ ì„ë² ë”© ìƒì„± ì¤‘...")
        contents = chunk_df['content'].tolist()
        embeddings = model.encode(contents, show_progress_bar=True)
        print(f"âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {embeddings.shape}")
        
        # 3. Milvusì— ë°ì´í„° ì¤€ë¹„
        print("\n3ï¸âƒ£  Milvus ì‚½ì… ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        milvus_data = [
            [f"{row['case_id']}_chunk_{row['id']}" for _, row in chunk_df.iterrows()],
            chunk_df['case_id'].tolist(),
            chunk_df['level'].tolist(),
            contents,
            embeddings.tolist()
        ]
        print("âœ“ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        
        # 4. Milvusì— ì‚½ì…
        print("\n4ï¸âƒ£  Milvus Collectionì— ë°ì´í„° ì‚½ì…...")
        insert_result = collection.insert(
            milvus_data,
            field_names=['chunk_id', 'case_id', 'level', 'content', 'embedding']
        )
        
        print(f"âœ“ ë°ì´í„° ì‚½ì… ì™„ë£Œ!")
        print(f"  - ì‚½ì…ëœ í–‰: {len(insert_result.primary_keys)}")
        print(f"  - Primary Keys (ìƒ˜í”Œ): {insert_result.primary_keys[:5]}")
        
        # 5. Collection flush
        print("\n5ï¸âƒ£  Collection flush (ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°)...")
        collection.flush()
        print("âœ“ Flush ì™„ë£Œ")
        
        # 6. í†µê³„ ì •ë³´ ì¶œë ¥
        print("\n6ï¸âƒ£  Collection í†µê³„:")
        print(f"  - Database: legal_db")
        print(f"  - Collection: legal_chunks_v1")
        print(f"  - ì´ ì²­í¬ ìˆ˜: {collection.num_entities}")
        print(f"  - ìˆ˜ì¤€ë³„ ë¶„í¬:")
        for level in chunk_df['level'].unique():
            count = len(chunk_df[chunk_df['level'] == level])
            print(f"    â€¢ {level}: {count}ê°œ")
        
        return True
    
    except Exception as e:
        print(f"âœ— ì„ë² ë”© ìƒì„±/ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜: PostgreSQL â†’ Chunking â†’ Milvus"""
    
    if not MILVUS_AVAILABLE:
        print("âœ— Milvus ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("  ì„¤ì¹˜: pip install pymilvus sentence-transformers")
        return False
    
    print("\n" + "ğŸš€"*30)
    print("ğŸ“š ë²•ë¥  ë¬¸ì„œ ì²­í‚¹ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("ğŸš€"*30)
    
    # 1ë‹¨ê³„: PostgreSQLì—ì„œ ë°ì´í„° ë¡œë“œ
    master_df, chunk_df = load_from_postgres_and_chunk()
    
    if chunk_df is None or len(chunk_df) == 0:
        print("\nâœ— ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDF ETL íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return False
    
    # 2ë‹¨ê³„: Milvus Collection ì´ˆê¸°í™”
    collection = initialize_milvus_collection()
    
    if collection is None:
        print("\nâœ— Milvus Collection ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    # 3ë‹¨ê³„: ì„ë² ë”© ìƒì„± ë° ì €ì¥
    success = generate_and_store_embeddings(chunk_df, collection)
    
    if success:
        print("\n" + "âœ¨"*30)
        print("âœ… ì²­í‚¹ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("âœ¨"*30)
        print("\nğŸ“Š ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. Attu UI ì ‘ì†: http://localhost:8000")
        print("  2. Database: legal_db ì„ íƒ")
        print("  3. Collection: legal_chunks_v1 í´ë¦­")
        print("  4. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ë²•ë¥  ì¡°í•­ ê²€ìƒ‰")
        return True
    else:
        print("\nâœ— ì²­í‚¹ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
        return False

if __name__ == "__main__":
    main()

# ============================================================
# Airflow DAG ì •ì˜
# ============================================================

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def chunk_data_task(**kwargs):
    """Airflow íƒœìŠ¤í¬ë¡œ ì‚¬ìš©í•  ì²­í‚¹ í•¨ìˆ˜"""
    main()

if MILVUS_AVAILABLE:
    with DAG(
        dag_id='legal_chunking_milvus_v1',
        description='PostgreSQLì˜ ë²•ë¥  ë°ì´í„°ë¥¼ Milvusë¡œ ì²­í‚¹',
        start_date=datetime(2024, 1, 1),
        schedule_interval=None,  # ìˆ˜ë™ íŠ¸ë¦¬ê±°
        catchup=False,
        tags=['legal', 'chunking', 'milvus']
    ) as dag:
        
        chunking_task = PythonOperator(
            task_id='chunk_legal_documents',
            python_callable=chunk_data_task,
            op_kwargs={},
            provide_context=True
        )
else:
    logger.warning("ì²­í‚¹ DAG ë¡œë“œ ì‹¤íŒ¨: Milvus ì˜ì¡´ì„± ëˆ„ë½ (pymilvus, sentence-transformers)")
    dag = None