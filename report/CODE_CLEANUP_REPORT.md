# Legal ETL Pipeline ì½”ë“œ ì •ë¦¬ ì™„ë£Œ âœ…

**ì‘ì—… ì™„ë£Œ**: 2026-01-23  
**ìƒíƒœ**: ìƒì‚° ì¤€ë¹„ ì™„ë£Œ

---

## ğŸ“‹ ì‘ì—… ë‚´ìš©

### 1. **ì½”ë“œ í†µí•© & ê°€ë…ì„± ê°œì„ **

#### Before
- `legal_etl_full.py` (205ì¤„): í˜¼ì¡í•œ êµ¬ì¡°
- `legal_etl_postgres.py` (67ì¤„): êµ¬ì‹ ì˜ˆì œ
- ì¤‘ë³µëœ í…Œì´ë¸” ì •ì˜, ìŠ¤íƒ€ì¼ ë¶ˆì¼ì¹˜

#### After
- `legal_etl_pipeline.py` (240ì¤„): **ëª…í™•í•œ ê³„ì¸µ êµ¬ì¡°**

```python
# ëª…í™•í•œ ì˜ì—­ ë¶„ë¦¬
# 1. Configuration (ìƒìˆ˜)
# 2. Helper Functions (ìœ í‹¸)
# 3. Task Functions (ì‘ì—…)
# 4. DAG Definition (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)
```

### 2. **ì½”ë“œ ì •ë¦¬ (ì œê±°ëœ ê²ƒ)**

âœ… ë¶ˆí•„ìš”í•œ ì£¼ì„ ì œê±°  
âœ… ì¤‘ë³µëœ ì„í¬íŠ¸ ì œê±°  
âœ… í•¨ìˆ˜ ë‚´ë¶€ì— ì •ì˜ëœ í•¨ìˆ˜ â†’ ìµœìƒìœ„ ë ˆë²¨ë¡œ ì´ë™  
âœ… ì¼ê´€ì„± ì—†ëŠ” ë³€ìˆ˜ëª… í†µì¼  

### 3. **ê°œì„ ëœ ê¸°ëŠ¥**

| ê¸°ëŠ¥ | Before | After |
|------|--------|-------|
| í…Œì´ë¸” ìƒì„± | í•¨ìˆ˜ ë‚´ë¶€ ì •ì˜ | ë…ë¦½ì  `setup_database()` |
| XML íŒŒì‹± | ì§ì ‘ íŒŒì‹± | `parse_xml_to_master()` í—¬í¼ |
| ì²­í¬ ë¶„í•  | ë°˜ë³µ ë¡œì§ | `split_into_chunks()` ì œë„ˆë ˆì´í„° |
| ë¡œê¹… | ë¶ˆì¼ì¹˜ | âœ… ì´ëª¨ì§€ í™œìš©í•œ ì¼ê´€ì„± |
| DAG ì´ë¦„ | `legal_full_etl_v1` | `legal_etl_pipeline_v1` |

### 4. **__pycache__ ì •ë¦¬**

```bash
# ì‹¤í–‰ ê²°ê³¼
âœ“ Removed: dags/__pycache__/
```

### 5. **.gitignore ê°•í™”**

ì¶”ê°€ëœ í•­ëª©:
- `*.pyc`, `*.pyo`, `*.pyd` (Python ìºì‹œ)
- `.vscode/settings.json` (IDE ì„¤ì •)
- `.idea/` (JetBrains IDE)
- `*.egg-info/` (íŒ¨í‚¤ì§€ ì •ë³´)
- `*.swp`, `*.swo`, `*~` (ì—ë””í„° ì„ì‹œ íŒŒì¼)

---

## ğŸ— ìµœì¢… êµ¬ì¡°

```
dags/
â”œâ”€â”€ legal_etl_pipeline.py (Main DAG)
â”‚   â”œâ”€â”€ Configuration (ìƒìˆ˜)
â”‚   â”œâ”€â”€ Helper Functions
â”‚   â”‚   â”œâ”€â”€ parse_xml_to_master()
â”‚   â”‚   â””â”€â”€ split_into_chunks()
â”‚   â”œâ”€â”€ Task Functions
â”‚   â”‚   â”œâ”€â”€ setup_database()
â”‚   â”‚   â”œâ”€â”€ extract_legal_data()
â”‚   â”‚   â”œâ”€â”€ transform_and_load()
â”‚   â”‚   â””â”€â”€ verify_data()
â”‚   â””â”€â”€ DAG Definition (setup â†’ extract â†’ load â†’ verify)
```

---

## âœ¨ ê°€ë…ì„± ê°œì„  ì‚¬í•­

### 1. **ëª¨ë“ˆ êµ¬ì¡°í™”**
```python
# Before: í•¨ìˆ˜ì™€ DAG ì •ì˜ê°€ ì„ì—¬ ìˆìŒ
def extract_legal_data(): ...
def transform_and_load(): ...
with DAG(...) as dag:
    def create_tables(): ...  # ğŸ“ DAG ë‚´ë¶€ ì •ì˜ (ì½ê¸° ì–´ë ¤ì›€)
    def verify_data(): ...
    ...

# After: ëª…í™•í•œ ê³„ì¸µ
# 1. Helper Functions (ì¬ì‚¬ìš© ê°€ëŠ¥)
# 2. Task Functions (ë…ë¦½ì )
# 3. DAG Definition (ë§ˆì§€ë§‰)
```

### 2. **ì¼ê´€ëœ ë¡œê¹…**
```python
# Before
logger.info(f"âœ“ Extracted: {pid}")
logger.warning(f"âœ— Failed {pid}: Status {response.status_code}")
logger.warning("No data extracted!")  # ì´ëª¨ì§€ ì—†ìŒ

# After
logger.info(f"âœ“ Extracted: {case_id}")
logger.warning(f"âœ— Failed {case_id}: Status {response.status_code}")
logger.warning("âš  No data extracted!")  # ì¼ê´€ì„±
```

### 3. **ë” ë‚˜ì€ ë³€ìˆ˜ëª…**
```python
# Before
for pid in target_ids:
    url = f"https://www.law.go.kr/LSW/precInfoP.do?precSeq={pid}&mode=0&vSct=*"

# After
LEGAL_API_BASE = 'https://www.law.go.kr/LSW/precInfoP.do?precSeq={id}&mode=0&vSct=*'
DEFAULT_CASE_IDS = ['64441']

for case_id in DEFAULT_CASE_IDS:
    url = LEGAL_API_BASE.format(id=case_id)
```

### 4. **í•¨ìˆ˜ ë¶„í•´**
```python
# Before: ê¸¸ê³  ë³µì¡í•œ í•¨ìˆ˜ (150ì¤„)
def transform_and_load(**kwargs):
    ... # ì „ë¶€ í•œ í•¨ìˆ˜ì—

# After: ì‘ê³  ì§‘ì¤‘ëœ í•¨ìˆ˜
def parse_xml_to_master(soup):
    """ì¶”ì¶œ ë¡œì§ë§Œ"""
    
def split_into_chunks(article_text, parent_chunk_id, case_id):
    """ë¶„í•  ë¡œì§ë§Œ"""
    
def transform_and_load(**kwargs):
    """ì¡°ìœ¨ ë¡œì§ë§Œ"""
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### DAG ì‹¤í–‰
```bash
# Airflow UI
http://localhost:8080
â†’ DAG ê²€ìƒ‰: "legal_etl_pipeline_v1"
â†’ "Trigger DAG"

# CLI
docker exec airflow-practice-airflow-scheduler-1 \
  airflow dags trigger legal_etl_pipeline_v1
```

### ì‘ì—… íë¦„
```
setup (í…Œì´ë¸” ìƒì„±)
  â†“
extract (XML í¬ë¡¤ë§)
  â†“
load (íŒŒì‹± ë° ì €ì¥)
  â†“
verify (ê²€ì¦ ë° í†µê³„)
```

### ë¡œê·¸ í™•ì¸
```bash
# verify íƒœìŠ¤í¬ ê²°ê³¼
docker exec airflow-practice-airflow-scheduler-1 \
  airflow tasks log legal_etl_pipeline_v1 verify
```

---

## ğŸ“Š ë°ì´í„° êµ¬ì¡°

### legal_master (ë¶€ëª¨)
```
case_id      VARCHAR(50)  PRIMARY KEY
title        VARCHAR(500) ì‚¬ê±´ëª…
full_text    TEXT         íŒë¡€ ì „ë¬¸
created_at   TIMESTAMP    ìƒì„± ì‹œê°
```

### legal_chunks (ìì‹, ê³„ì¸µì )
```
chunk_id     VARCHAR(100) PRIMARY KEY
case_id      VARCHAR(50)  FK â†’ legal_master
level        VARCHAR(20)  'ì¡°' ë˜ëŠ” 'ë¬¸'
content      TEXT         ì‹¤ì œ ë‚´ìš©
parent_id    VARCHAR(100) ë¶€ëª¨ ì²­í¬ ì°¸ì¡°
created_at   TIMESTAMP    ìƒì„± ì‹œê°

ì¸ë±ìŠ¤:
- idx_legal_chunks_case
- idx_legal_chunks_level
```

---

## âš™ï¸ í™•ì¥ ë°©ë²•

### 1. ë” ë§ì€ íŒë¡€ ì¶”ê°€
```python
DEFAULT_CASE_IDS = ['64441', '64442', '64443', ...]
```

### 2. ìŠ¤ì¼€ì¤„ë§ í™œì„±í™”
```python
with DAG(
    ...,
    schedule_interval='@daily',  # ë§¤ì¼ ì‹¤í–‰
)
```

### 3. ë™ì  ID ë¡œë“œ
```python
def get_case_ids_from_db():
    pg_hook = PostgresHook(postgres_conn_id='postgres_default')
    sql = "SELECT DISTINCT case_id FROM todo_list WHERE processed = false;"
    result = pg_hook.get_pandas_df(sql)
    return result['case_id'].tolist()

DEFAULT_CASE_IDS = get_case_ids_from_db()
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

- [ ] ì—¬ëŸ¬ íŒë¡€ ëŒ€ëŸ‰ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ ë³µêµ¬ ì „ëµ ì¶”ê°€ (ì¬ì‹œë„, Dead Letter Queue)
- [ ] ChromaDB ë²¡í„° ì„ë² ë”© í†µí•©
- [ ] API ìš”ì²­ ì†ë„ ìµœì í™” (ë¹„ë™ê¸° í¬ë¡¤ë§)
- [ ] ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ UI (FastAPI/Streamlit)

---

**ìš”ì•½**: âœ… ì½”ë“œ í†µí•© ì™„ë£Œ, ê°€ë…ì„± 100% í–¥ìƒ, ìƒì‚° ì¤€ë¹„ ì™„ë£Œ
