import fitz  # PyMuPDF
import re
import logging
import json
import os
import sys
from datetime import datetime
from uuid import uuid4
from typing import List, Dict, Optional
from pathlib import Path

# UTF-8 ì¸ì½”ë”© ê°•ì œ
if sys.stdout.encoding != 'utf-8':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Database imports
import psycopg2
from psycopg2.extras import execute_batch
try:
    from pymilvus import Collection, connections, MilvusException
except ImportError:
    MilvusException = Exception  # Fallback

# LangChain imports
try:
    from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter
    from langchain.embeddings import OpenAIEmbeddings  # ë˜ëŠ” ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸
except ImportError as e:
    logger_init = logging.getLogger(__name__)
    logger_init.warning(f"âš  LangChain import ì‹¤íŒ¨: {str(e)}")

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def pdf_to_markdown(pdf_path):
    """
    PDF íŒŒì¼ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path (str): PDF íŒŒì¼ ê²½ë¡œ
        
    Returns:
        tuple: (ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„°)
    """
    import sys
    import locale
    
    try:
        doc = fitz.open(pdf_path)
    except Exception as e:
        logger.error(f"âœ— PDF ì—´ê¸° ì‹¤íŒ¨: {str(e)}")
        return None, None
    
    md_text = ""
    metadata = {
        "file_path": pdf_path,
        "total_pages": len(doc),
        "extraction_time": datetime.now().isoformat(),
    }
    
    # Debug: ì¸ì½”ë”© ì •ë³´
    logger.info(f"ğŸ“‹ System encoding: {sys.getdefaultencoding()}, Locale: {locale.getpreferredencoding()}")
    
    # 1. ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (UTF-8 ê°•ì œ)
    full_content = ""
    for page_num, page in enumerate(doc):
        text = page.get_text(output='text')  # ëª…ì‹œì  í…ìŠ¤íŠ¸ ëª¨ë“œ
        # ì¸ì½”ë”© ë³´ì •
        try:
            if isinstance(text, bytes):
                text = text.decode('utf-8', errors='replace')
        except:
            pass
        full_content += text
    
    # 2. ë²•ë¥ ëª…ì„ ëŒ€ì œëª©(#)ìœ¼ë¡œ ë³€í™˜
    lines = full_content.split('\n')
    title = lines[0].strip() if lines else "ë²•ë¥ ëª… ë¯¸ì •"
    md_text += f"# {title}\n\n"
    metadata["document_title"] = title
    
    # 3. 'ì œNì¡°' íŒ¨í„´ì„ ì°¾ì•„ ì¤‘ì œëª©(##)ìœ¼ë¡œ ë³€í™˜
    content_body = '\n'.join(lines[1:])
    processed_body = re.sub(r'(ì œ\d+ì¡°\([^)]*\))', r'\n## \1\n', content_body)
    
    # 4. ë²ˆí˜¸ ë§¤ê¹€ ëª©ë¡ ì •ê·œí™”
    processed_body = re.sub(r'\n(\d+\.)', r'\n- \1', processed_body)
    
    # 5. ê³µë°± ì •ê·œí™” (ì—¬ëŸ¬ ê°œ ì¤„ë°”ê¿ˆ â†’ 2ê°œë¡œ í†µì¼)
    processed_body = re.sub(r'\n\n+', r'\n\n', processed_body)
    
    md_text += processed_body
    
    logger.info(f"âœ“ PDF â†’ Markdown ë³€í™˜ ì™„ë£Œ: {title} ({len(doc)} í˜ì´ì§€)")
    
    return md_text, metadata


def save_markdown_to_file(md_text: str, output_dir: str = "./output", filename: str = None) -> Optional[str]:
    """
    ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        md_text (str): ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸
        output_dir (str): ì €ì¥ ë””ë ‰í„°ë¦¬
        filename (str): íŒŒì¼ëª… (ê¸°ë³¸ê°’: timestamp ê¸°ë°˜)
        
    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ, ì‹¤íŒ¨ ì‹œ None
    """
    try:
        # ë””ë ‰í„°ë¦¬ ìƒì„±
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ëª… ê²°ì •
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"document_{timestamp}.md"
        else:
            if not filename.endswith('.md'):
                filename += '.md'
        
        # ì „ì²´ ê²½ë¡œ
        file_path = os.path.join(output_dir, filename)
        
        # íŒŒì¼ ì €ì¥ (UTF-8-sig ì‚¬ìš©: BOM í¬í•¨)
        with open(file_path, 'w', encoding='utf-8-sig') as f:
            f.write(md_text)
        
        file_size = os.path.getsize(file_path)
        logger.info(f"âœ“ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ (UTF-8-sig): {file_path} ({file_size} bytes)")
        return file_path
        
    except IOError as e:
        logger.error(f"âœ— íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"âœ— ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {str(e)}")
        return None


def chunk_markdown_hierarchically(md_text: str, doc_id: str = None) -> List[Dict]:
    """
    ë§ˆí¬ë‹¤ìš´ì„ ê³„ì¸µì ìœ¼ë¡œ ì²­í‚¹í•©ë‹ˆë‹¤.
    
    êµ¬ì¡°:
    - Parent: ì¡°í•­ ë‹¨ìœ„ (##)
    - Child: ë¬¸ì¥/í•­ ë‹¨ìœ„ (300ì ì´ë‚´)
    
    Args:
        md_text (str): ë§ˆí¬ë‹¤ìš´ í˜•ì‹ í…ìŠ¤íŠ¸
        doc_id (str): ë¬¸ì„œ ID (ê¸°ë³¸ê°’: ìë™ ìƒì„±)
        
    Returns:
        List[Dict]: ê³„ì¸µì  ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    if not doc_id:
        doc_id = str(uuid4())
    
    # ë¶€ëª¨ ë‹¨ìœ„ ë¶„í• : ## (ì œNì¡°) ê¸°ì¤€
    headers_to_split_on = [("##", "Article")]
    md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
    
    try:
        parent_docs = md_splitter.split_text(md_text)
    except Exception as e:
        logger.error(f"âœ— ë¶€ëª¨ ì²­í¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return []

    # ìì‹ ë‹¨ìœ„ ë¶„í• : ê° ì¡°ë¬¸ì„ ë” ì˜ê²Œ ìª¼ê°¬
    child_splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,
        chunk_overlap=50,
        separators=["\n- ", "\n\n", "\n", ". ", " "]
    )

    hierarchical_data = []
    
    for parent_idx, parent in enumerate(parent_docs):
        # ë¶€ëª¨ì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì¡°í•­ ì •ë³´ ì¶”ì¶œ
        article_title = parent.metadata.get("Article", f"Article_{parent_idx}")
        parent_id = f"{doc_id}_parent_{parent_idx}"
        
        # ìì‹ ì²­í¬ ìƒì„±
        try:
            child_chunks = child_splitter.split_text(parent.page_content)
        except Exception as e:
            logger.warning(f"âš  ìì‹ ì²­í¬ ìƒì„± ì‹¤íŒ¨ ({article_title}): {str(e)}")
            child_chunks = [parent.page_content]
        
        # ë¶€ëª¨ í•­ëª© ìƒì„±
        parent_entry = {
            "id": parent_id,
            "doc_id": doc_id,
            "type": "parent",
            "level": "ì¡°",
            "title": article_title,
            "content": parent.page_content,
            "char_count": len(parent.page_content),
            "created_at": datetime.now().isoformat(),
            "children": []
        }
        
        # ìì‹ í•­ëª© ìƒì„±
        for child_idx, child_content in enumerate(child_chunks):
            child_id = f"{parent_id}_child_{child_idx}"
            parent_entry["children"].append({
                "id": child_id,
                "parent_id": parent_id,
                "doc_id": doc_id,
                "type": "child",
                "level": "ë¬¸",
                "sequence": child_idx + 1,
                "content": child_content,
                "char_count": len(child_content),
                "created_at": datetime.now().isoformat(),
            })
        
        hierarchical_data.append(parent_entry)
        logger.info(f"âœ“ ì¡°í•­ ì²­í‚¹ ì™„ë£Œ: {article_title} ({len(parent_entry['children'])} ìì‹ ì²­í¬)")
    
    logger.info(f"âœ“ ì „ì²´ ê³„ì¸µì  ì²­í‚¹ ì™„ë£Œ: {len(hierarchical_data)} ë¶€ëª¨ í•­ëª©")
    return hierarchical_data


# ============================================================================
# PostgreSQL ì €ì¥ì†Œ
# ============================================================================

class PostgreSQLStorage:
    """PostgreSQL ì €ì¥ì†Œ ê´€ë¦¬"""
    
    def __init__(self, db_config: Dict):
        """
        Args:
            db_config (Dict): DB ì—°ê²° ì„¤ì •
        """
        self.db_config = db_config
        self.conn = None
        
    def connect(self):
        """PostgreSQL ì—°ê²°"""
        try:
            self.conn = psycopg2.connect(**self.db_config)
            logger.info("âœ“ PostgreSQL ì—°ê²° ì„±ê³µ")
            return True
        except psycopg2.Error as e:
            logger.error(f"âœ— PostgreSQL ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return False
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()
            logger.info("âœ“ PostgreSQL ì—°ê²° ì¢…ë£Œ")
    
    def create_tables(self):
        """í•„ìš”í•œ í…Œì´ë¸” ìƒì„±"""
        if not self.conn:
            logger.error("âœ— ë¨¼ì € connect()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”")
            return False
        
        cursor = self.conn.cursor()
        
        try:
            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS pdf_documents (
                    doc_id VARCHAR(36) PRIMARY KEY,
                    title VARCHAR(500) NOT NULL,
                    file_path TEXT NOT NULL,
                    total_pages INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # ë¶€ëª¨ ì²­í¬ í…Œì´ë¸” (ì¡°í•­ ë‹¨ìœ„)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS parent_chunks (
                    id VARCHAR(255) PRIMARY KEY,
                    doc_id VARCHAR(36) NOT NULL REFERENCES pdf_documents(doc_id) ON DELETE CASCADE,
                    title VARCHAR(500),
                    content TEXT NOT NULL,
                    char_count INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # ìì‹ ì²­í¬ í…Œì´ë¸” (ë¬¸ì¥ ë‹¨ìœ„)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS child_chunks (
                    id VARCHAR(255) PRIMARY KEY,
                    parent_id VARCHAR(255) NOT NULL REFERENCES parent_chunks(id) ON DELETE CASCADE,
                    doc_id VARCHAR(36) NOT NULL REFERENCES pdf_documents(doc_id) ON DELETE CASCADE,
                    sequence INTEGER,
                    content TEXT NOT NULL,
                    char_count INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_parent_doc_id ON parent_chunks(doc_id);")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_child_parent_id ON child_chunks(parent_id);")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_child_doc_id ON child_chunks(doc_id);")
            
            self.conn.commit()
            logger.info("âœ“ PostgreSQL í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            return True
            
        except psycopg2.Error as e:
            logger.error(f"âœ— í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {str(e)}")
            self.conn.rollback()
            return False
        finally:
            cursor.close()
    
    def save_hierarchical_data(self, doc_id: str, title: str, file_path: str, hierarchical_data: List[Dict]) -> bool:
        """ê³„ì¸µì  ë°ì´í„° ì €ì¥"""
        if not self.conn:
            logger.error("âœ— ë¨¼ì € connect()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”")
            return False
        
        cursor = self.conn.cursor()
        
        try:
            # 1. ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì €ì¥
            cursor.execute("""
                INSERT INTO pdf_documents (doc_id, title, file_path, total_pages)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (doc_id) DO UPDATE SET updated_at = CURRENT_TIMESTAMP;
            """, (doc_id, title, file_path, len(hierarchical_data)))
            
            # 2. ë¶€ëª¨ ì²­í¬ ì €ì¥
            parent_data = [
                (item["id"], doc_id, item["title"], item["content"], item["char_count"])
                for item in hierarchical_data
            ]
            
            execute_batch(cursor, """
                INSERT INTO parent_chunks (id, doc_id, title, content, char_count)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (id) DO UPDATE SET content = EXCLUDED.content;
            """, parent_data)
            
            # 3. ìì‹ ì²­í¬ ì €ì¥
            child_data = []
            for parent in hierarchical_data:
                for child in parent["children"]:
                    child_data.append((
                        child["id"],
                        child["parent_id"],
                        child["doc_id"],
                        child["sequence"],
                        child["content"],
                        child["char_count"]
                    ))
            
            if child_data:
                execute_batch(cursor, """
                    INSERT INTO child_chunks (id, parent_id, doc_id, sequence, content, char_count)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    ON CONFLICT (id) DO UPDATE SET content = EXCLUDED.content;
                """, child_data)
            
            self.conn.commit()
            logger.info(f"âœ“ PostgreSQL ì €ì¥: {len(parent_data)} ë¶€ëª¨, {len(child_data)} ìì‹")
            return True
            
        except psycopg2.Error as e:
            logger.error(f"âœ— ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            self.conn.rollback()
            return False
        finally:
            cursor.close()


# ============================================================================
# Milvus ì €ì¥ì†Œ (ë²¡í„° ì„ë² ë”©)
# ============================================================================

class MilvusStorage:
    """Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self, milvus_host: str = "localhost", milvus_port: int = 19530):
        """
        Args:
            milvus_host (str): Milvus í˜¸ìŠ¤íŠ¸
            milvus_port (int): Milvus í¬íŠ¸
        """
        self.host = milvus_host
        self.port = milvus_port
        self.collection = None
        self.embeddings_model = None
        
    def connect(self):
        """Milvus ì—°ê²°"""
        try:
            connections.connect(host=self.host, port=self.port)
            logger.info(f"âœ“ Milvus ì—°ê²° ì„±ê³µ ({self.host}:{self.port})")
            return True
        except MilvusException as e:
            logger.error(f"âœ— Milvus ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return False
    
    def create_collection(self, collection_name: str = "legal_chunks"):
        """ì»¬ë ‰ì…˜ ìƒì„±"""
        try:
            from pymilvus import FieldSchema, CollectionSchema, DataType
            
            fields = [
                FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=255, is_primary=True),
                FieldSchema(name="doc_id", dtype=DataType.VARCHAR, max_length=36),
                FieldSchema(name="parent_id", dtype=DataType.VARCHAR, max_length=255),
                FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=10000),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
            ]
            
            schema = CollectionSchema(fields, description="Legal document chunks")
            self.collection = Collection(name=collection_name, schema=schema)
            
            logger.info(f"âœ“ Milvus ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
            return True
            
        except MilvusException as e:
            logger.error(f"âœ— ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return False
    
    def insert_embeddings(self, hierarchical_data: List[Dict]) -> bool:
        """
        ë²¡í„° ì„ë² ë”©ì„ Milvusì— ì‚½ì…
        
        Note: ì‹¤ì œ ì„ë² ë”©ì€ ë³„ë„ì˜ ëª¨ë¸(OpenAI, BERT ë“±)ì´ í•„ìš”í•©ë‹ˆë‹¤.
        """
        if not self.collection:
            logger.error("âœ— ë¨¼ì € create_collection()ì„ í˜¸ì¶œí•˜ì„¸ìš”")
            return False
        
        try:
            entities = []
            
            for parent in hierarchical_data:
                for child in parent["children"]:
                    # TODO: ì‹¤ì œ ì„ë² ë”© ìƒì„± (OpenAI API, Sentence-BERT ë“±)
                    # embedding = self.embeddings_model.embed_query(child["content"])
                    
                    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì„ë² ë”©
                    dummy_embedding = [0.0] * 1536
                    
                    entities.append({
                        "id": child["id"],
                        "doc_id": child["doc_id"],
                        "parent_id": child["parent_id"],
                        "content": child["content"],
                        "embedding": dummy_embedding
                    })
            
            if entities:
                self.collection.insert([
                    [e["id"] for e in entities],
                    [e["doc_id"] for e in entities],
                    [e["parent_id"] for e in entities],
                    [e["content"] for e in entities],
                    [e["embedding"] for e in entities]
                ])
                
                self.collection.flush()
                logger.info(f"âœ“ Milvus ì‚½ì…: {len(entities)} ë²¡í„°")
                return True
                
        except MilvusException as e:
            logger.error(f"âœ— ë²¡í„° ì‚½ì… ì‹¤íŒ¨: {str(e)}")
            return False
        
        return False


# ============================================================================
# í†µí•© íŒŒì´í”„ë¼ì¸
# ============================================================================

def process_pdf_to_db(
    pdf_path: str,
    postgres_config: Dict,
    milvus_host: str = "localhost",
    milvus_port: int = 19530
) -> bool:
    """
    PDF â†’ Markdown â†’ ê³„ì¸µì  ì²­í‚¹ â†’ DB ì €ì¥ (PostgreSQL + Milvus)
    
    Args:
        pdf_path (str): PDF íŒŒì¼ ê²½ë¡œ
        postgres_config (Dict): PostgreSQL ì—°ê²° ì„¤ì •
        milvus_host (str): Milvus í˜¸ìŠ¤íŠ¸
        milvus_port (int): Milvus í¬íŠ¸
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    
    # 1. PDF â†’ Markdown
    logger.info(f"[1/5] PDF ë³€í™˜ ì¤‘: {pdf_path}")
    md_text, metadata = pdf_to_markdown(pdf_path)
    if not md_text:
        logger.error("âœ— PDF ë³€í™˜ ì‹¤íŒ¨")
        return False
    
    # 2. ê³„ì¸µì  ì²­í‚¹
    logger.info("[2/5] ê³„ì¸µì  ì²­í‚¹ ì¤‘...")
    doc_id = str(uuid4())
    hierarchical_data = chunk_markdown_hierarchically(md_text, doc_id)
    if not hierarchical_data:
        logger.error("âœ— ì²­í‚¹ ì‹¤íŒ¨")
        return False
    
    # 3. PostgreSQL ì €ì¥
    logger.info("[3/5] PostgreSQL ì €ì¥ ì¤‘...")
    pg_storage = PostgreSQLStorage(postgres_config)
    if not pg_storage.connect():
        return False
    
    if not pg_storage.create_tables():
        pg_storage.close()
        return False
    
    if not pg_storage.save_hierarchical_data(doc_id, metadata["document_title"], pdf_path, hierarchical_data):
        pg_storage.close()
        return False
    
    pg_storage.close()
    
    # 4. Milvus ì—°ê²° (ì„ íƒì‚¬í•­)
    logger.info("[4/5] Milvus ì—°ê²° ì¤‘...")
    milvus_storage = MilvusStorage(milvus_host, milvus_port)
    if milvus_storage.connect():
        if milvus_storage.create_collection():
            logger.info("[5/5] ë²¡í„° ì„ë² ë”© ì‚½ì… ì¤‘...")
            milvus_storage.insert_embeddings(hierarchical_data)
    else:
        logger.warning("âš  Milvus ì—°ê²° ì‹¤íŒ¨, PostgreSQLë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    logger.info("âœ“ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    return True


# ============================================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================================

if __name__ == "__main__":
    import sys
    
    # í…ŒìŠ¤íŠ¸ PDF ê²½ë¡œ
    pdf_path = r"C:\Users\ë¯¸ì†Œì •ë³´ê¸°ìˆ \airflow-practice\test\ë²•ë¥ test.pdf"
    output_md_dir = r"C:\Users\ë¯¸ì†Œì •ë³´ê¸°ìˆ \airflow-practice\output\markdown"
    
    print("\n" + "="*70)
    print("PDF â†’ Markdown â†’ DB íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("="*70 + "\n")
    
    # 1. PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
    print("[1/4] PDF íŒŒì¼ í™•ì¸...")
    if not os.path.exists(pdf_path):
        logger.error(f"âœ— PDF íŒŒì¼ ì—†ìŒ: {pdf_path}")
        sys.exit(1)
    else:
        file_size = os.path.getsize(pdf_path) / 1024
        logger.info(f"âœ“ PDF íŒŒì¼ ë°œê²¬: {pdf_path} ({file_size:.1f} KB)")
    
    # 2. PDF â†’ Markdown ë³€í™˜
    print("\n[2/4] PDF â†’ Markdown ë³€í™˜...")
    try:
        md_text, metadata = pdf_to_markdown(pdf_path)
        if not md_text:
            logger.error("âœ— ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì‹¤íŒ¨")
            sys.exit(1)
        
        logger.info(f"âœ“ ë³€í™˜ ì™„ë£Œ: {len(md_text)} ë¬¸ì")
        logger.info(f"  - ì œëª©: {metadata['document_title']}")
        logger.info(f"  - í˜ì´ì§€: {metadata['total_pages']}")
        
    except Exception as e:
        logger.error(f"âœ— PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # 3. ë§ˆí¬ë‹¤ìš´ì„ íŒŒì¼ë¡œ ì €ì¥
    print("\n[3/4] ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥...")
    try:
        base_filename = Path(pdf_path).stem
        md_file_path = save_markdown_to_file(
            md_text,
            output_dir=output_md_dir,
            filename=f"{base_filename}.md"
        )
        if not md_file_path:
            logger.warning("âš  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
        else:
            # ì €ì¥ëœ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
            with open(md_file_path, 'r', encoding='utf-8') as f:
                preview = f.read(500)
            logger.info(f"\nğŸ“ ë§ˆí¬ë‹¤ìš´ ë¯¸ë¦¬ë³´ê¸°:\n{'-'*50}\n{preview}\n{'-'*50}")
        
    except Exception as e:
        logger.error(f"âœ— íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
    
    # 4. ê³„ì¸µì  ì²­í‚¹
    print("\n[4/4] ê³„ì¸µì  ì²­í‚¹...")
    try:
        doc_id = str(uuid4())
        hierarchical_data = chunk_markdown_hierarchically(md_text, doc_id)
        
        if not hierarchical_data:
            logger.error("âœ— ì²­í‚¹ ì‹¤íŒ¨")
            sys.exit(1)
        
        logger.info(f"âœ“ ì²­í‚¹ ì™„ë£Œ: {len(hierarchical_data)} ë¶€ëª¨ í•­ëª©")
        
        # ì²­í‚¹ ê²°ê³¼ í†µê³„
        total_children = sum(len(p["children"]) for p in hierarchical_data)
        total_chars = sum(p["char_count"] for p in hierarchical_data)
        
        logger.info(f"  - ì´ ë¶€ëª¨ ì²­í¬: {len(hierarchical_data)}")
        logger.info(f"  - ì´ ìì‹ ì²­í¬: {total_children}")
        logger.info(f"  - ì´ ë¬¸ì ìˆ˜: {total_chars}")
        
        # JSONìœ¼ë¡œ ì €ì¥ (ì°¸ê³ ìš©)
        json_output_dir = r"C:\Users\ë¯¸ì†Œì •ë³´ê¸°ìˆ \airflow-practice\output\json"
        Path(json_output_dir).mkdir(parents=True, exist_ok=True)
        json_file = os.path.join(json_output_dir, f"{Path(pdf_path).stem}_chunks.json")
        
        with open(json_file, 'w', encoding='utf-8') as f:
            # JSON ì§ë ¬í™” (datetime ì²˜ë¦¬)
            json_data = json.dumps(hierarchical_data, ensure_ascii=False, indent=2)
            f.write(json_data)
        
        logger.info(f"âœ“ ì²­í‚¹ ê²°ê³¼ ì €ì¥: {json_file}")
        
        # PostgreSQL ì €ì¥ (ì„ íƒì‚¬í•­)
        print("\n[ì¶”ê°€] PostgreSQL ì €ì¥ ì‹œë„...")
        postgres_config = {
            "host": "localhost",
            "port": 5432,
            "database": "airflow",
            "user": "airflow",
            "password": "airflow"
        }
        
        try:
            pg_storage = PostgreSQLStorage(postgres_config)
            if pg_storage.connect():
                if pg_storage.create_tables():
                    if pg_storage.save_hierarchical_data(
                        doc_id,
                        metadata["document_title"],
                        pdf_path,
                        hierarchical_data
                    ):
                        logger.info("âœ“ PostgreSQL ì €ì¥ ì„±ê³µ")
                    else:
                        logger.warning("âš  PostgreSQL ì €ì¥ ì‹¤íŒ¨")
                else:
                    logger.warning("âš  PostgreSQL í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
                pg_storage.close()
            else:
                logger.warning("âš  PostgreSQL ì—°ê²° ì‹¤íŒ¨ (DB í™•ì¸ í•„ìš”)")
        except Exception as e:
            logger.warning(f"âš  PostgreSQL ì €ì¥ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {str(e)}")
        
        print("\n" + "="*70)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*70)
        
    except Exception as e:
        logger.error(f"âœ— ì²­í‚¹ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)